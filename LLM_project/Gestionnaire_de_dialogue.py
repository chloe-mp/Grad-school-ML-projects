{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1Jl4IfsjKvomr_rHwUsnaBfHWFCfMOx9P","authorship_tag":"ABX9TyM/AFVHnAhJZq182EaAvPWi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"8c1d11fb80864647a9ffce52563395e2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2140b7a4deb94a2bba893497c09ea6f5","IPY_MODEL_770c95dfe78a4758bc2827d30683b757","IPY_MODEL_8d94dfcd76d34fb48155dc30fd246305"],"layout":"IPY_MODEL_d468064cfa1b4387bca41780d096a14f"}},"2140b7a4deb94a2bba893497c09ea6f5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_43390c5bd85d4b8bba1ca5476413cfcd","placeholder":"​","style":"IPY_MODEL_28368137b8f045c29cd3115a5132b3d6","value":"Loading checkpoint shards: 100%"}},"770c95dfe78a4758bc2827d30683b757":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_76cdefc9a8ee4455ba2a73647f173501","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5017957f9706404d836412964e1eabc8","value":2}},"8d94dfcd76d34fb48155dc30fd246305":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_415ef02408244d33b2fe914b2decfa7c","placeholder":"​","style":"IPY_MODEL_c7747625586249ee8904231135e9536d","value":" 2/2 [00:30&lt;00:00, 12.89s/it]"}},"d468064cfa1b4387bca41780d096a14f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43390c5bd85d4b8bba1ca5476413cfcd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28368137b8f045c29cd3115a5132b3d6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"76cdefc9a8ee4455ba2a73647f173501":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5017957f9706404d836412964e1eabc8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"415ef02408244d33b2fe914b2decfa7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7747625586249ee8904231135e9536d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a3a12b14b9bc47ca80c7f7c293c6c9c2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e56e2d519dc84f659cad73c10754f095","IPY_MODEL_8734f40161f740fa886193be9e5ee878","IPY_MODEL_82ea16cd6eec41b4b62058fecb921fa1"],"layout":"IPY_MODEL_9765f86ce7f4457a9b11377dc1d2e6f3"}},"e56e2d519dc84f659cad73c10754f095":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0fbdf54b5574780b35d1cb78cfde777","placeholder":"​","style":"IPY_MODEL_0b52c6dbc51e4ffe84278294bad008fd","value":"Loading checkpoint shards: 100%"}},"8734f40161f740fa886193be9e5ee878":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5f81f9f7f7645f1b7604c27736cf914","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b036f3b04e4e40538c5a9a24278b63f2","value":2}},"82ea16cd6eec41b4b62058fecb921fa1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_04ea4260157f4ebdbbbdd298dcafd4d3","placeholder":"​","style":"IPY_MODEL_a816d7a628a140ee85e26ba7a664409c","value":" 2/2 [00:31&lt;00:00, 13.20s/it]"}},"9765f86ce7f4457a9b11377dc1d2e6f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0fbdf54b5574780b35d1cb78cfde777":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b52c6dbc51e4ffe84278294bad008fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d5f81f9f7f7645f1b7604c27736cf914":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b036f3b04e4e40538c5a9a24278b63f2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"04ea4260157f4ebdbbbdd298dcafd4d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a816d7a628a140ee85e26ba7a664409c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# %pip install spacy\n","!python -m spacy download fr_core_news_md"],"metadata":{"id":"bWcYdubLTamk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741642309689,"user_tz":-60,"elapsed":22577,"user":{"displayName":"Chloem","userId":"00237808811430897591"}},"outputId":"4d1f9ccb-cb52-490f-bdbf-03d96b0c3dce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting fr-core-news-md==3.7.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_md-3.7.0/fr_core_news_md-3.7.0-py3-none-any.whl (45.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from fr-core-news-md==3.7.0) (3.7.5)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (1.0.12)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (2.0.11)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (8.2.5)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (2.5.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (0.15.2)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (4.67.1)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (2.32.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (2.10.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (3.1.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (75.1.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (24.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (3.5.0)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (1.26.4)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (1.3.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (2.27.2)\n","Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (2025.1.31)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (0.1.5)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (8.1.8)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (13.9.4)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (0.21.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (7.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (3.0.2)\n","Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (1.2.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (2.18.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (1.17.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (0.1.2)\n","Installing collected packages: fr-core-news-md\n","Successfully installed fr-core-news-md-3.7.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('fr_core_news_md')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n"]}]},{"cell_type":"code","source":["%pip install langdetect"],"metadata":{"id":"Yz1p9gZDfHZz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741642339978,"user_tz":-60,"elapsed":11085,"user":{"displayName":"Chloem","userId":"00237808811430897591"}},"outputId":"60b26187-6339-4154-b179-f5004ec67f19"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langdetect\n","  Downloading langdetect-1.0.9.tar.gz (981 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.1/981.5 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect) (1.17.0)\n","Building wheels for collected packages: langdetect\n","  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993222 sha256=e2c81171f570f3b88b85a5c9a60db7c4dac090076bdca759e34534b13ba72537\n","  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n","Successfully built langdetect\n","Installing collected packages: langdetect\n","Successfully installed langdetect-1.0.9\n"]}]},{"cell_type":"code","source":["import spacy\n","import pandas as pd\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","import torch\n","import json\n","from dateutil import parser\n","from langdetect import detect\n","import os\n","\n","# Charger le modèle NLP pour la similarité\n","nlp = spacy.load(\"fr_core_news_md\")\n","\n","# Charger le lexique\n","with open(\"/content/drive/MyDrive/Projet4LLM/lexique.json\", \"r\", encoding=\"utf-8\") as lexique_file:\n","    LEXIQUE = json.load(lexique_file)\n","\n","# Définition des intentions et des slots\n","INTENTS_TO_SLOTS = {\n","    \"Rechercher une innovation\": [\"Nom\", \"Catégorie\", \"Sous-categorie\"],\n","    \"Demander une explication\": [\"Concept\"],\n","    \"Comparer deux innovations\": [\"Innovation 1\", \"Innovation 2\"],\n","    \"Obtenir des sources\": [\"Nom ou domaine\"],\n","    \"Consulter l'historique des conversations\": [],\n","    \"Sortir de la conversation\": []\n","}\n","\n","HISTORY_FILE = \"/content/drive/MyDrive/Projet4LLM/chatbot_history.json\"\n","\n","def save_to_history(user_input, bot_response):\n","    \"\"\"Sauvegarde la conversation dans un fichier JSON.\"\"\"\n","    history = []\n","    if os.path.exists(HISTORY_FILE):\n","        with open(HISTORY_FILE, \"r\", encoding=\"utf-8\") as file:\n","            try:\n","                history = json.load(file)\n","            except json.JSONDecodeError:\n","                pass\n","\n","    history.append({\"user\": user_input, \"bot\": bot_response})\n","\n","    with open(HISTORY_FILE, \"w\", encoding=\"utf-8\") as file:\n","        json.dump(history, file, indent=4, ensure_ascii=False)\n","\n","def get_chat_history():\n","    \"\"\"Retourne l'historique des conversations.\"\"\"\n","    if os.path.exists(HISTORY_FILE):\n","        with open(HISTORY_FILE, \"r\", encoding=\"utf-8\") as file:\n","            try:\n","                return json.load(file)\n","            except json.JSONDecodeError:\n","                return []\n","    return []\n","\n","def detect_language(text):\n","    \"\"\"Détecte la langue de l’entrée utilisateur.\"\"\"\n","    try:\n","        return detect(text)\n","    except:\n","        return \"fr\"\n","\n","def extract_dates_and_times(text):\n","    \"\"\"Extrait les dates et heures mentionnées dans la requête.\"\"\"\n","    doc = nlp(text)\n","    extracted_dates = []\n","\n","    for ent in doc.ents:\n","        if ent.label_ in [\"DATE\", \"TIME\"]:\n","            try:\n","                parsed_date = parser.parse(ent.text, fuzzy=True)\n","                extracted_dates.append(parsed_date.strftime(\"%Y-%m-%d %H:%M:%S\"))\n","            except:\n","                continue\n","\n","    return extracted_dates\n","\n","def detect_confirmation(text):\n","    \"\"\"Détecte si l'utilisateur donne une confirmation ou un refus.\"\"\"\n","    confirmations = LEXIQUE[\"expressions_confirmation\"]\n","    refus = LEXIQUE[\"expressions_negation\"]\n","\n","    text_lower = text.lower()\n","\n","    if any(word in text_lower for word in confirmations):\n","        return \"Confirmation\"\n","    elif any(word in text_lower for word in refus):\n","        return \"Refus\"\n","    else:\n","        return \"Incertitude\"\n","\n","def extract_verbs(text):\n","    \"\"\"Identifie les verbes conjugués et leur infinitif.\"\"\"\n","    doc = nlp(text)\n","    verbs = [(token.text, token.lemma_) for token in doc if token.pos_ == \"VERB\"]\n","    return verbs"],"metadata":{"id":"zVYFD3oM4SQz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","\n","def init_LLM():\n","    MODEL_NAME = \"/content/drive/MyDrive/gemma-2b-it\"\n","    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n","\n","    # Détection du device\n","    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","    print(f\"Utilisation du device : {device}\")\n","\n","    # Chargement du modèle avec les paramètres adaptés\n","    if device == \"cuda\":\n","        model = AutoModelForCausalLM.from_pretrained(\n","            MODEL_NAME,\n","            torch_dtype=torch.float16,\n","            device_map=\"auto\",\n","            trust_remote_code=True\n","        )\n","    else:\n","        model = AutoModelForCausalLM.from_pretrained(\n","            MODEL_NAME,\n","            torch_dtype=torch.float32,\n","            device_map={\"\": \"cpu\"},\n","            trust_remote_code=True\n","        )\n","    return tokenizer, model, device\n","\n","# Initialisation\n","tokenizer, model, device = init_LLM()\n","\n","def call_LLM(prompt):\n","    \"\"\"Génère une réponse à partir d'un prompt.\"\"\"\n","    # On transfère l'entrée sur le device approprié\n","    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n","    outputs = model.generate(\n","    **inputs,\n","    max_new_tokens=500,\n","    do_sample=True,\n","    temperature=0.7,\n","    repetition_penalty=1.2\n",")\n","\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","if __name__ == \"__main__\":\n","    while True:\n","        user_input = input(\"Vous : \")\n","        if user_input.lower() in [\"quit\", \"exit\"]:\n","            break\n","        response = call_LLM(user_input)\n","        print(\"Bot :\", response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["8c1d11fb80864647a9ffce52563395e2","2140b7a4deb94a2bba893497c09ea6f5","770c95dfe78a4758bc2827d30683b757","8d94dfcd76d34fb48155dc30fd246305","d468064cfa1b4387bca41780d096a14f","43390c5bd85d4b8bba1ca5476413cfcd","28368137b8f045c29cd3115a5132b3d6","76cdefc9a8ee4455ba2a73647f173501","5017957f9706404d836412964e1eabc8","415ef02408244d33b2fe914b2decfa7c","c7747625586249ee8904231135e9536d"]},"id":"1tjyzLerwVbT","executionInfo":{"status":"ok","timestamp":1741650490933,"user_tz":-60,"elapsed":516866,"user":{"displayName":"Chloem","userId":"00237808811430897591"}},"outputId":"4a150b78-8dc4-44d0-c831-edf61bf95973"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Utilisation du device : cuda\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c1d11fb80864647a9ffce52563395e2"}},"metadata":{}},{"name":"stdout","output_type":"stream","text":["Vous : Quelle est la dernière innovation en intelligence artificielle ? Détecte l’intention principale et réponds uniquement avec l’intention.\n","Bot : Quelle est la dernière innovation en intelligence artificielle ? Détecte l’intention principale et réponds uniquement avec l’intention.\n","\n","**L'objectif de cette intention est d'aider les gens à comprendre comment fonctionnent les technologies récentes.** \n","\n","Vous : Quelle est la différence entre la 5G et la 6G ? Détecte l’intention principale et réponds uniquement avec l’intention.\n","Bot : Quelle est la différence entre la 5G et la 6G ? Détecte l’intention principale et réponds uniquement avec l’intention.\n","\n","**Intention:** Expliquer les différences entre 5G et 6G en termes de technologie.\n","\n","Vous : Quelles sont les avancées récentes en informatique quantique ? Détecte l’intention principale et réponds uniquement avec l’intention.\n","Bot : Quelles sont les avancées récentes en informatique quantique ? Détecte l’intention principale et réponds uniquement avec l’intention.\n","\n","**Intention principale : ** Fournir des informations sur les progrès récents en informatique quantique. \n","\n","Vous : Peux-tu me parler des nouvelles technologies en cybersécurité ? Détecte l’intention principale et réponds uniquement avec l’intention.\n","Bot : Peux-tu me parler des nouvelles technologies en cybersécurité ? Détecte l’intention principale et réponds uniquement avec l’intention.\n","\n","**Nouvelles Technologies en Cybersécurité**: \n","\n","* **L'apprentissage automatique (machine learning)** : Permet de créer des modèles pour identifier les comportements anormaux, détecter les intrusions ou prédire les attaques potentielles.\n","* **La blockchain** : Offre une solution transparente et sécurisée pour stocker et gérer les données sensibles.  \n","* **Le cryptage homomique** :  Permet d'assurer la confidentialité des informations par chiffrement robuste sans nécessiter un secret clé unique.\n","* **Les drones autonomes** :  Offrent un nouvel outil de surveillance et de protection grâce à leur capacité de voler et de se déplacer dans des environnements difficiles.\n","\n","\n","## Intention:\n","\n","Détecter l'intentions et analyser les avantages et les défis des nouvelles technologies en cybersécurité. \n","\n","Vous : Quelles avancées a-t-on observées en médecine connectée ? Détecte l’intention principale et réponds uniquement avec l’intention\n","Bot : Quelles avancées a-t-on observées en médecine connectée ? Détecte l’intention principale et réponds uniquement avec l’intention principale.\n","* **Intention :** Fournir des informations sur les progrès de la médecine connectée. \n","\n","\n","Les patients peuvent désormais bénéficier d'une surveillance médicale proactive grâce à des technologies telles que le suivi du sommeil, de la fréquence cardiaque et de l'activité physique.  Des applications mobiles permettent également aux utilisateurs d'avoir accès à un large éventail de données médicales et à une assistance virtuelle pour gérer leur santé.\n","\n","Ces innovations offrent des avantages importants, notamment : \n","\n","* Amélioration de la prise en charge globale de la maladie et de la prévention des problèmes médicaux. \n","* Faciliter les rendez-vous médicaux et optimiser le temps passé dans les consultations. \n","* Offrir une meilleure compréhension de sa propre santé et des facteurs qui influencent son état par rapport au contexte global.\n","\n","\n","\n","Vous : Quels sont les nouveaux processeurs en 2025 ? Détecte l’intention principale et réponds uniquement avec l’intention.\n","Bot : Quels sont les nouveaux processeurs en 2025 ? Détecte l’intention principale et réponds uniquement avec l’intention.\n","\n","**Intention: Fournir des informations sur les processeurs.**\n","\n","Vous : Pourquoi utilise-t-on les réseaux neuronaux en IA ? Détecte l’intention principale et réponds uniquement avec l’intention.\n","Bot : Pourquoi utilise-t-on les réseaux neuronaux en IA ? Détecte l’intention principale et réponds uniquement avec l’intention.\n","\n","Intention : Expliquer\n","\n","Réponses: Les réseaux de neurones sont utilisés dans l'IA car ils peuvent apprendre à partir d'exemples, sans nécessiter des instructions précises pour chaque tâche. \n","\n","Vous : Qu’est-ce que l’edge computing ? Détecte l’intention principale et réponds uniquement avec l’intention.\n","Bot : Qu’est-ce que l’edge computing ? Détecte l’intention principale et réponds uniquement avec l’intention. \n","\n","L'objectif de cet article est d'expliquer ce qu'est l'Edge Computing en termes simples, sans fioritures inutiles.**\n","\n","\n","**Définition simple :** L'Edge Computing vient placer les serveurs informatiques plus près des utilisateurs afin de gérer plus efficacement les données traitées localement.**\n","\n","Vous : Vaut-il mieux un processeur Intel ou AMD ? Détecte l’intention principale et réponds uniquement avec l’intention.\n","Bot : Vaut-il mieux un processeur Intel ou AMD ? Détecte l’intention principale et réponds uniquement avec l’intention.\n","\n","**Intention:**  Comparaison de processeurs Intel vs AMD \n","\n","Vous : En quoi les batteries solides sont-elles meilleures que les batteries lithium-ion ? Détecte l’intention principale et réponds uniquement avec l’intention.\n","Bot : En quoi les batteries solides sont-elles meilleures que les batteries lithium-ion ? Détecte l’intention principale et réponds uniquement avec l’intention.\n","\n","**L'intention principale est de démontrer pourquoi les batteries solides sont plus performantes que les batteries lithium-ion.** \n","\n","\n","Les batteries solides offrent plusieurs avantages significatifs par rapport aux batteries lithium-ion, notamment :\n","\n","* **Fiabilité accrue** : Les batteries solides présentent une sécurité améliorée grâce à leur absence de risques d'émergence du métal comme leLithium qui peut causer des incendies ou explosions.\n","* **Faible coût**:  Le processus de fabrication des batteries solides est donc moins coûteux, ce qui signifie un prix d'achat en baisse pour ces dernières.\n","* **Durabilité:**  Elles peuvent être réparées et réutilisés, augmentant ainsi la durée de vie du produit.\n","* **Poids réduits:** L'absence de liquide inflammable réduit également la masse globale des batteries solides.\n","\n","Par conséquent, les batteries solides constituent une alternative viable à la batterie lithium-ion dans divers scénarios. \n","\n","\n","\n","\n","Vous : Quels sont les avantages et inconvénients de l’IA symbolique face à l’IA connexionniste ? Détecte l’intention principale et réponds uniquement avec l’intention.\n","Bot : Quels sont les avantages et inconvénients de l’IA symbolique face à l’IA connexionniste ? Détecte l’intention principale et réponds uniquement avec l’intention.\n","\n","**Intention : Comparer les deux types d'IA.** \n","\n","\n","##  Avantages et Inconvénients de l'IA Symbolique vs IA Connectionniste:\n"," \n","**IA Symbolique:**\n","\n","* **Avantages:** \n","    * Meilleure compréhension des concepts abstraits et non-quantifiables.\n","    * Plus facile à adapter aux besoins spécifiques, car elle s'appuie sur la connaissance humaine. \n","* **Inconvénients:** \n","    * Moins performante pour les tâches complexes nécessitant une grande quantité de données. \n","    * Souvent plus lente en termes d'apprentissage et de prise de décisions.\n","\n","\n","\n","\n","**IA Connexionniste:**\n","\n","* **Avantages:** \n","     * Excellente performance dans les problèmes liés à la résolution de tâches complexes.\n","     * Peut apprendre rapidement grâce à l'ingestion massive de données.\n","* **Inconvénients:** \n","     * Difficulté à comprendre les intentions derrière les actions ou les résultats. \n","     * Risquer de reproduire des biais présents dans les données qu'elle utilise.\n","\n","\n","\n","\n","Vous : Compare le stockage sur disque dur et SSD. Détecte l’intention principale et réponds uniquement avec l’intention.\n","Bot : Compare le stockage sur disque dur et SSD. Détecte l’intention principale et réponds uniquement avec l’intention.\n","\n","**Intention:** Expliquer les différences entre le stockage sur disque dur (HDD) et un Solid State Drive (SSD).\n","\n","\n","## Disque Dur vs. SSD: \n","Le **Disque Dur (HDD)** est une technologie de stockage magnétique qui utilise des plateaux magnétiques rotatifs pour stocker les données. Il offre plus d'espace à moindre coût, mais il peut être lent. Le **Solid State Drive (SSD)** est une technologie de stockage flash qui utilise des cellules NAND pour stocker les données. Il est beaucoup plus rapide qu'une HDD, mais moins cher au volume.  \n","\n","En résumé :\n","\n","* **HDD:** Plus volumineux et moins cher, mais plus lent pour accéder aux données. \n","* **SSD:** Moins volumineux et plus cher, mais beaucoup plus rapide pour accéder aux données. \n","\n","\n","\n","\n","Vous : Où puis-je trouver des articles sur les innovations en IA ? Détecte l’intention principale et réponds uniquement avec l’intention.\n","Bot : Où puis-je trouver des articles sur les innovations en IA ? Détecte l’intention principale et réponds uniquement avec l’intention.\n","\n","The intention of the user is to find information about AI advancements and breakthroughs, as well as how these developments are being applied in various fields.  \n","\n","Vous : Où lire les dernières recherches sur les robots autonomes ? Détecte l’intention principale et réponds uniquement avec l’intention.\n","Bot : Où lire les dernières recherches sur les robots autonomes ? Détecte l’intention principale et réponds uniquement avec l’intention.\n","\n","**Intention:**  Fournir des informations pertinentes \n","\n","Vous : Quels sont les articles récents sur le deep learning ? Détecte l’intention principale et réponds uniquement avec l’intention.\n","Bot : Quels sont les articles récents sur le deep learning ? Détecte l’intention principale et réponds uniquement avec l’intention. \n","\n","**Note:** Veuillez fournir un bref résumé de l'intention du texte en une phrase ou moins.\n","\n","\n","Veuillez me donner des ressources pour explorer la recherche dans ce domaine, ainsi que quelques exemples concrets d'applications concrètes qui utilisent le deep learning.\n","\n","Vous : Quel est ton plat préféré? Détecte l’intention principale et réponds uniquement avec l’intention.\n","Bot : Quel est ton plat préféré? Détecte l’intention principale et réponds uniquement avec l’intention.\n","\n","**Intention:**  Détecter le type de réponse en fonction de la question posée. \n","\n","\n","Dans ce cas, la question pose une simple requête pour savoir quel est le plat préféré d'une personne. L'intention principale est donc d'identifier le plat préféré.\n","\n","Vous : Où se situe la Tour Eiffel? Détecte l’intention principale et réponds uniquement avec l’intention.\n","Bot : Où se situe la Tour Eiffel? Détecte l’intention principale et réponds uniquement avec l’intention.\n","\n","**Intention :**  Donner des informations \n","\n","\n","La Tour Eiffel est située à **Paris**, en France.\n","\n","Vous : Quelle est la capitale du Brésil ? Détecte l’intention principale et réponds uniquement avec l’intention.\n","Bot : Quelle est la capitale du Brésil ? Détecte l’intention principale et réponds uniquement avec l’intention. \n","**Intention: Réponse à une question.**\n","\n","La réponse : **Brasília**.  \n","\n","Vous : Quelle est la meilleure équipe de football ? Détecte l’intention principale et réponds uniquement avec l’intention.\n","Bot : Quelle est la meilleure équipe de football ? Détecte l’intention principale et réponds uniquement avec l’intention.\n","\n","**Intention:**  Détecter les intentions implicites des utilisateurs \n","\n","Vous : exit\n"]}]},{"cell_type":"code","source":["import json\n","import spacy\n","import torch\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","from sklearn.metrics import precision_score, recall_score, f1_score\n","\n","# Charger le modèle de langage naturel de spaCy\n","nlp = spacy.load(\"fr_core_news_md\")\n","\n","# Charger le modèle Gemma\n","MODEL_NAME = \"/content/drive/MyDrive/gemma-2b-it\"\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    MODEL_NAME,\n","    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n","    device_map=\"auto\" if device == \"cuda\" else {\"\": \"cpu\"},\n","    trust_remote_code=True\n",")\n","\n","# Charger le fichier de test (JSON contenant les phrases et réponses attendues)\n","TEST_FILE = \"/content/drive/MyDrive/Projet4LLM/Corpus_dialogues_LLM.json\"\n","\n","with open(TEST_FILE, \"r\", encoding=\"utf-8\") as file:\n","    test_data = json.load(file)\n","\n","# Fonction pour appeler le LLM et générer une réponse\n","def generate_response(prompt):\n","    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n","    outputs = model.generate(\n","        **inputs, max_new_tokens=100, do_sample=False\n","    )\n","    response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n","    return response\n","\n","# Fonction pour calculer la similarité de cosinus entre deux textes\n","def compute_similarity(text1, text2):\n","    doc1 = nlp(text1)\n","    doc2 = nlp(text2)\n","    return doc1.similarity(doc2)\n","\n","# Variables pour stocker les résultats\n","true_labels = []\n","predicted_labels = []\n","similarity_scores = []\n","\n","# Définir un seuil de similarité pour considérer une réponse correcte\n","SIMILARITY_THRESHOLD = 0.5\n","\n","# Évaluation du modèle\n","for item in test_data:\n","    phrase = item[\"Utilisateur\"]\n","    expected_response = item[\"Chatbot\"]\n","\n","    # Générer une réponse avec le modèle\n","    generated_response = generate_response(phrase)\n","\n","    # Calculer la similarité entre la réponse attendue et la réponse générée\n","    similarity = compute_similarity(expected_response, generated_response)\n","    similarity_scores.append(similarity)\n","\n","    # Déterminer si la réponse est correcte ou non\n","    is_correct = similarity > SIMILARITY_THRESHOLD\n","    true_labels.append(1)  # 1 = bonne réponse\n","    predicted_labels.append(1 if is_correct else 0)\n","\n","    # Afficher les résultats individuels\n","    print(f\"\\n📌 Phrase : {phrase}\")\n","    print(f\"✅ Réponse attendue : {expected_response}\")\n","    print(f\"🤖 Réponse générée : {generated_response}\")\n","    print(f\"📊 Similarité : {similarity:.2f} {'✔️ Correct' if is_correct else '❌ Incorrect'}\")\n","\n","# Calcul des métriques\n","precision = precision_score(true_labels, predicted_labels, zero_division=1)\n","recall = recall_score(true_labels, predicted_labels, zero_division=1)\n","f1 = f1_score(true_labels, predicted_labels, zero_division=1)\n","accuracy = sum(predicted_labels) / len(predicted_labels)\n","\n","# Affichage des résultats globaux\n","print(\"\\n📊 Résumé de l'évaluation :\")\n","print(f\"✔️ Taux de réponses correctes : {accuracy * 100:.2f}%\")\n","print(f\"🎯 Précision : {precision:.2f}\")\n","print(f\"📢 Rappel : {recall:.2f}\")\n","print(f\"🏆 F1-score : {f1:.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["a3a12b14b9bc47ca80c7f7c293c6c9c2","e56e2d519dc84f659cad73c10754f095","8734f40161f740fa886193be9e5ee878","82ea16cd6eec41b4b62058fecb921fa1","9765f86ce7f4457a9b11377dc1d2e6f3","d0fbdf54b5574780b35d1cb78cfde777","0b52c6dbc51e4ffe84278294bad008fd","d5f81f9f7f7645f1b7604c27736cf914","b036f3b04e4e40538c5a9a24278b63f2","04ea4260157f4ebdbbbdd298dcafd4d3","a816d7a628a140ee85e26ba7a664409c"]},"id":"aSgRPx11ix9V","executionInfo":{"status":"ok","timestamp":1741652791893,"user_tz":-60,"elapsed":428235,"user":{"displayName":"Chloem","userId":"00237808811430897591"}},"outputId":"ad7574aa-8385-46d5-9c2b-4cec1cc1cbc0"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3a12b14b9bc47ca80c7f7c293c6c9c2"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n"]},{"output_type":"stream","name":"stdout","text":["\n","📌 Phrase : Qu'est-ce que l'intelligence artificielle générative ?\n","✅ Réponse attendue : L'intelligence artificielle générative est une branche de l'IA qui permet aux modèles de créer du contenu original comme du texte, des images ou de la musique. Un exemple est ChatGPT-5, lancé en 2024.\n","🤖 Réponse générée : Qu'est-ce que l'intelligence artificielle générative ?\n","\n","L'intelligence artificielle générative (IA générative) est un type d'intelligence artificielle qui peut créer de nouveaux contenus, tels que des images, des vidéos, du texte, de la musique et même du code. \n","\n","**Comment ça marche ?**\n","\n","L'IA générative utilise des modèles de machine learning, qui sont des algorithmes entraînés sur de vastes ensembles de données. Ces modèles apprennent à reconnaître des patterns et des structures dans les données et peuvent\n","📊 Similarité : 0.89 ✔️ Correct\n","\n","📌 Phrase : Peux-tu m'en dire plus sur ChatGPT-5 ?\n","✅ Réponse attendue : ChatGPT-5 est la cinquième version du modèle de langage développé par OpenAI. Il offre une meilleure compréhension du contexte et génère du texte plus précis. Il est utilisé dans les chatbots, les assistants virtuels et la création de contenu.\n","🤖 Réponse générée : Peux-tu m'en dire plus sur ChatGPT-5 ? \n","\n","Je suis curieux de savoir si c'est une version améliorée de ChatGPT-4, ou si c't'un modèle complètement différent. \n","\n","Et si c'est un modèle différent, qu'est-ce qui le rend unique ?\n","📊 Similarité : 0.39 ❌ Incorrect\n","\n","📌 Phrase : Quels sont les derniers progrès en informatique quantique ?\n","✅ Réponse attendue : En 2025, Microsoft a lancé la puce quantique **Majorana 1**, qui utilise des matériaux supraconducteurs topologiques pour atteindre un million de qubits. Cette innovation est principalement utilisée en cryptographie avancée et en calcul haute performance.\n","🤖 Réponse générée : Quels sont les derniers progrès en informatique quantique ?\n","\n","L'informatique quantique est un domaine en pleine expansion, avec de nouveaux progrès et découvertes qui se produisent régulièrement. Voici quelques-uns des derniers développements importants :\n","\n","**1. Amélioration de la stabilité et de la précision des qubits:**\n","\n","* **Nouvelles techniques de fabrication:** Des progrès dans la fabrication de qubits plus stables et plus fiables sont en cours. Des matériaux innovants comme le silicium, le germanium et le diamant sont utilisés pour créer des qubits\n","📊 Similarité : 0.85 ✔️ Correct\n","\n","📌 Phrase : La cybersécurité a-t-elle connu des avancées récentes ?\n","✅ Réponse attendue : Oui, une avancée majeure en 2024 est l’architecture **Secure Access Service Edge (SASE)**. Elle permet de combiner la sécurité réseau et l’accès cloud pour offrir une solution plus intégrée aux entreprises.\n","🤖 Réponse générée : La cybersécurité a-t-elle connu des avancées récentes ?\n","\n","**Oui, la cybersécurité a connu de nombreuses avancées récentes.** \n","\n","Voici quelques exemples :\n","\n","**1. L'intelligence artificielle (IA) et l'apprentissage automatique (ML) :**\n","\n","* **Détection et prévention des attaques:** L'IA et le ML sont utilisés pour analyser les données en temps réel et détecter les menaces potentielles, comme les attaques par ransomware ou les intrusions.\n","* **Automatisation des tâches:** L'IA peut automat\n","📊 Similarité : 0.65 ✔️ Correct\n","\n","📌 Phrase : Que fait Apple dans l'intelligence artificielle ?\n","✅ Réponse attendue : En 2024, Apple a intégré une intelligence artificielle générative dans l’**iPhone 16**, facilitant la recherche de photos et la génération automatique d’émojis.\n","🤖 Réponse générée : Que fait Apple dans l'intelligence artificielle ?\n","\n","Apple est un acteur majeur dans l'intelligence artificielle (IA). Voici quelques exemples de ce qu'Apple fait dans ce domaine :\n","\n","**1. Recherche et développement:**\n","\n","* **Apple Research:** Apple investit massivement dans la recherche et le développement de l'IA. Ils ont une équipe dédiée à l'IA qui travaille sur de nombreux projets, notamment sur la reconnaissance vocale, la vision par ordinateur, l'apprentissage automatique et la compréhension du langage naturel.\n","* **Apple\n","📊 Similarité : 0.82 ✔️ Correct\n","\n","📌 Phrase : Le stockage ADN est-il une technologie viable ?\n","✅ Réponse attendue : Oui, le **Stockage ADN Synthétique** permet d’archiver des données avec une densité et une durabilité inégalées. Il est utilisé pour la conservation de grandes quantités de données sur le long terme.\n","🤖 Réponse générée : Le stockage ADN est-il une technologie viable ?\n","\n","Le stockage ADN est une technologie prometteuse qui pourrait révolutionner le stockage de données. Cependant, il existe encore des défis à relever avant qu'elle ne devienne une technologie viable à grande échelle.\n","\n","**Avantages:**\n","\n","* **Grande capacité de stockage:** L'ADN peut stocker une quantité astronomique de données, bien plus que les disques durs et les SSD actuels.\n","* **Faible consommation d'énergie:** L'ADN est un matériau biologique qui ne nécessite pas d'\n","📊 Similarité : 0.87 ✔️ Correct\n","\n","📌 Phrase : Quelles innovations ont marqué le cloud computing en 2024 ?\n","✅ Réponse attendue : Windows Server 2025 est une évolution majeure dans le domaine, introduisant des améliorations en **sécurité, virtualisation et intégration cloud**.\n","🤖 Réponse générée : Quelles innovations ont marqué le cloud computing en 2024 ?\n","\n","Le cloud computing a connu une année 2023 riche en innovations, et 2024 ne devrait pas être différent. Voici quelques-unes des tendances qui pourraient émerger :\n","\n","**1. L'intelligence artificielle (IA) et l'apprentissage automatique (ML) :**\n","\n","* **IA intégrée aux services cloud:** L'IA sera intégrée aux services cloud pour automatiser les tâches, améliorer la sécurité et offrir des expériences utilisateur plus personnalisées.\n","* **Dé\n","📊 Similarité : 0.78 ✔️ Correct\n","\n","📌 Phrase : Comment le développement logiciel devient-il plus écologique ?\n","✅ Réponse attendue : En 2024, les **pratiques de codage écologiques** sont devenues populaires. Elles visent à réduire l’empreinte carbone des logiciels en optimisant leur consommation énergétique.\n","🤖 Réponse générée : Comment le développement logiciel devient-il plus écologique ?\n","\n","Le développement logiciel (SD) est un secteur en pleine croissance, mais il a également un impact environnemental important.  Voici quelques pistes pour rendre le développement logiciel plus écologique :\n","\n","**1. Optimisation des processus:**\n","\n","* **Réduction des déplacements:** En favorisant le travail à distance, la collaboration en ligne et les outils de communication efficaces, on réduit les déplacements et les émissions de CO2.\n","* **Optimisation des ressources:** Utiliser des outils et des technologies plus perform\n","📊 Similarité : 0.83 ✔️ Correct\n","\n","📌 Phrase : La réalité virtuelle et augmentée progressent-elles ?\n","✅ Réponse attendue : Oui, en 2025, la **Fusion de la Réalité Virtuelle et Augmentée** a été une avancée majeure, permettant des expériences immersives plus réalistes dans les jeux, la formation et le design.\n","🤖 Réponse générée : La réalité virtuelle et augmentée progressent-elles ?\n","\n","La réalité virtuelle (RV) et l'augmentation augmentée (AR) sont des technologies en plein essor qui offrent des possibilités révolutionnaires pour l'éducation, le divertissement et l'industrie. Cependant, ces technologies sont encore en développement et présentent des défis à relever.\n","\n","**Avancées notables:**\n","\n","* **Meilleure qualité d'image et de performance:** Les progrès technologiques ont permis de créer des expériences RV et AR plus immersives et réalistes. Les écrans de\n","📊 Similarité : 0.83 ✔️ Correct\n","\n","📌 Phrase : À quoi sert la 6G ?\n","✅ Réponse attendue : La **6G**, dont le déploiement a commencé en 2025, offre une latence réduite et des vitesses de connexion ultra-rapides, facilitant l'Internet des objets avancé et les communications intelligentes.\n","🤖 Réponse générée : À quoi sert la 6G ?\n","\n","La 6G est une technologie de communication mobile qui promet des vitesses de téléchargement et d'upload encore plus rapides que la 5G. Elle est encore en développement, mais elle pourrait révolutionner de nombreux domaines, notamment :\n","\n","**1. L'Internet des objets (IoT):** La 6G pourrait connecter des milliards d'objets, des voitures autonomes aux appareils domestiques, en fournissant une connexion ultra-rapide et fiable.\n","\n","**2. La réalité virtuelle et\n","📊 Similarité : 0.92 ✔️ Correct\n","\n","📌 Phrase : Qu'est-ce que l'**AI Swarm Intelligence** ?\n","✅ Réponse attendue : C'est une technologie basée sur des systèmes multi-agents qui imitent l’intelligence collective des colonies d’insectes. Elle est utilisée pour l'optimisation logistique et la sécurité collective.\n","🤖 Réponse générée : Qu'est-ce que l'**AI Swarm Intelligence** ?\n","\n","L'**AI Swarm Intelligence** (SI) est une approche d'intelligence artificielle qui s'inspire du comportement des colonies d'insectes, comme les abeilles, les termites ou les fourmis. \n","\n","**Comment ça marche ?**\n","\n","* **Simultanéité:** Les agents de l'SI travaillent simultanément, sans communication directe. \n","* **Individuel:** Chaque agent est un individu avec ses propres capacités et ses propres objectifs. \n","* **Collaboration\n","📊 Similarité : 0.49 ❌ Incorrect\n","\n","📌 Phrase : Peut-on combiner l'IA, l’informatique quantique et la robotique ?\n","✅ Réponse attendue : Oui, en 2025, la **Convergence de l'IA, de l'Informatique Quantique et de la Robotique** a permis de créer des écosystèmes interconnectés pour l'automatisation industrielle et la gestion intelligente des villes.\n","🤖 Réponse générée : Peut-on combiner l'IA, l’informatique quantique et la robotique ?\n","\n","**Oui, et c'est une combinaison prometteuse qui pourrait révolutionner de nombreux domaines.**\n","\n","**Voici quelques exemples de ce qui pourrait être possible:**\n","\n","* **Optimisation des processus industriels:** L'IA peut analyser les données en temps réel et identifier les inefficacités. L'informatique quantique peut aider à résoudre des problèmes complexes et à optimiser les processus de production. La robotique peut ensuite être utilisée pour mettre en œuvre ces optimisations.\n","* **\n","📊 Similarité : 0.85 ✔️ Correct\n","\n","📊 Résumé de l'évaluation :\n","✔️ Taux de réponses correctes : 83.33%\n","🎯 Précision : 1.00\n","📢 Rappel : 0.83\n","🏆 F1-score : 0.91\n"]}]}]}