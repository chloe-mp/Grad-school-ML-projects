{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1Jl4IfsjKvomr_rHwUsnaBfHWFCfMOx9P","authorship_tag":"ABX9TyM/AFVHnAhJZq182EaAvPWi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"8c1d11fb80864647a9ffce52563395e2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2140b7a4deb94a2bba893497c09ea6f5","IPY_MODEL_770c95dfe78a4758bc2827d30683b757","IPY_MODEL_8d94dfcd76d34fb48155dc30fd246305"],"layout":"IPY_MODEL_d468064cfa1b4387bca41780d096a14f"}},"2140b7a4deb94a2bba893497c09ea6f5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_43390c5bd85d4b8bba1ca5476413cfcd","placeholder":"‚Äã","style":"IPY_MODEL_28368137b8f045c29cd3115a5132b3d6","value":"Loading‚Äácheckpoint‚Äáshards:‚Äá100%"}},"770c95dfe78a4758bc2827d30683b757":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_76cdefc9a8ee4455ba2a73647f173501","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5017957f9706404d836412964e1eabc8","value":2}},"8d94dfcd76d34fb48155dc30fd246305":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_415ef02408244d33b2fe914b2decfa7c","placeholder":"‚Äã","style":"IPY_MODEL_c7747625586249ee8904231135e9536d","value":"‚Äá2/2‚Äá[00:30&lt;00:00,‚Äá12.89s/it]"}},"d468064cfa1b4387bca41780d096a14f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43390c5bd85d4b8bba1ca5476413cfcd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28368137b8f045c29cd3115a5132b3d6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"76cdefc9a8ee4455ba2a73647f173501":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5017957f9706404d836412964e1eabc8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"415ef02408244d33b2fe914b2decfa7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7747625586249ee8904231135e9536d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a3a12b14b9bc47ca80c7f7c293c6c9c2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e56e2d519dc84f659cad73c10754f095","IPY_MODEL_8734f40161f740fa886193be9e5ee878","IPY_MODEL_82ea16cd6eec41b4b62058fecb921fa1"],"layout":"IPY_MODEL_9765f86ce7f4457a9b11377dc1d2e6f3"}},"e56e2d519dc84f659cad73c10754f095":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0fbdf54b5574780b35d1cb78cfde777","placeholder":"‚Äã","style":"IPY_MODEL_0b52c6dbc51e4ffe84278294bad008fd","value":"Loading‚Äácheckpoint‚Äáshards:‚Äá100%"}},"8734f40161f740fa886193be9e5ee878":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5f81f9f7f7645f1b7604c27736cf914","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b036f3b04e4e40538c5a9a24278b63f2","value":2}},"82ea16cd6eec41b4b62058fecb921fa1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_04ea4260157f4ebdbbbdd298dcafd4d3","placeholder":"‚Äã","style":"IPY_MODEL_a816d7a628a140ee85e26ba7a664409c","value":"‚Äá2/2‚Äá[00:31&lt;00:00,‚Äá13.20s/it]"}},"9765f86ce7f4457a9b11377dc1d2e6f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0fbdf54b5574780b35d1cb78cfde777":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b52c6dbc51e4ffe84278294bad008fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d5f81f9f7f7645f1b7604c27736cf914":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b036f3b04e4e40538c5a9a24278b63f2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"04ea4260157f4ebdbbbdd298dcafd4d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a816d7a628a140ee85e26ba7a664409c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# %pip install spacy\n","!python -m spacy download fr_core_news_md"],"metadata":{"id":"bWcYdubLTamk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741642309689,"user_tz":-60,"elapsed":22577,"user":{"displayName":"Chloem","userId":"00237808811430897591"}},"outputId":"4d1f9ccb-cb52-490f-bdbf-03d96b0c3dce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting fr-core-news-md==3.7.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_md-3.7.0/fr_core_news_md-3.7.0-py3-none-any.whl (45.8 MB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m45.8/45.8 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from fr-core-news-md==3.7.0) (3.7.5)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (1.0.12)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (2.0.11)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (8.2.5)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (2.5.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (0.15.2)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (4.67.1)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (2.32.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (2.10.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (3.1.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (75.1.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (24.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (3.5.0)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (1.26.4)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (1.3.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (2.27.2)\n","Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (2025.1.31)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (0.1.5)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (8.1.8)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (13.9.4)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (0.21.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (7.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (3.0.2)\n","Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (1.2.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (2.18.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (1.17.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (0.1.2)\n","Installing collected packages: fr-core-news-md\n","Successfully installed fr-core-news-md-3.7.0\n","\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('fr_core_news_md')\n","\u001b[38;5;3m‚ö† Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n"]}]},{"cell_type":"code","source":["%pip install langdetect"],"metadata":{"id":"Yz1p9gZDfHZz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741642339978,"user_tz":-60,"elapsed":11085,"user":{"displayName":"Chloem","userId":"00237808811430897591"}},"outputId":"60b26187-6339-4154-b179-f5004ec67f19"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langdetect\n","  Downloading langdetect-1.0.9.tar.gz (981 kB)\n","\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m389.1/981.5 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect) (1.17.0)\n","Building wheels for collected packages: langdetect\n","  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993222 sha256=e2c81171f570f3b88b85a5c9a60db7c4dac090076bdca759e34534b13ba72537\n","  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n","Successfully built langdetect\n","Installing collected packages: langdetect\n","Successfully installed langdetect-1.0.9\n"]}]},{"cell_type":"code","source":["import spacy\n","import pandas as pd\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","import torch\n","import json\n","from dateutil import parser\n","from langdetect import detect\n","import os\n","\n","# Charger le mod√®le NLP pour la similarit√©\n","nlp = spacy.load(\"fr_core_news_md\")\n","\n","# Charger le lexique\n","with open(\"/content/drive/MyDrive/Projet4LLM/lexique.json\", \"r\", encoding=\"utf-8\") as lexique_file:\n","    LEXIQUE = json.load(lexique_file)\n","\n","# D√©finition des intentions et des slots\n","INTENTS_TO_SLOTS = {\n","    \"Rechercher une innovation\": [\"Nom\", \"Cat√©gorie\", \"Sous-categorie\"],\n","    \"Demander une explication\": [\"Concept\"],\n","    \"Comparer deux innovations\": [\"Innovation 1\", \"Innovation 2\"],\n","    \"Obtenir des sources\": [\"Nom ou domaine\"],\n","    \"Consulter l'historique des conversations\": [],\n","    \"Sortir de la conversation\": []\n","}\n","\n","HISTORY_FILE = \"/content/drive/MyDrive/Projet4LLM/chatbot_history.json\"\n","\n","def save_to_history(user_input, bot_response):\n","    \"\"\"Sauvegarde la conversation dans un fichier JSON.\"\"\"\n","    history = []\n","    if os.path.exists(HISTORY_FILE):\n","        with open(HISTORY_FILE, \"r\", encoding=\"utf-8\") as file:\n","            try:\n","                history = json.load(file)\n","            except json.JSONDecodeError:\n","                pass\n","\n","    history.append({\"user\": user_input, \"bot\": bot_response})\n","\n","    with open(HISTORY_FILE, \"w\", encoding=\"utf-8\") as file:\n","        json.dump(history, file, indent=4, ensure_ascii=False)\n","\n","def get_chat_history():\n","    \"\"\"Retourne l'historique des conversations.\"\"\"\n","    if os.path.exists(HISTORY_FILE):\n","        with open(HISTORY_FILE, \"r\", encoding=\"utf-8\") as file:\n","            try:\n","                return json.load(file)\n","            except json.JSONDecodeError:\n","                return []\n","    return []\n","\n","def detect_language(text):\n","    \"\"\"D√©tecte la langue de l‚Äôentr√©e utilisateur.\"\"\"\n","    try:\n","        return detect(text)\n","    except:\n","        return \"fr\"\n","\n","def extract_dates_and_times(text):\n","    \"\"\"Extrait les dates et heures mentionn√©es dans la requ√™te.\"\"\"\n","    doc = nlp(text)\n","    extracted_dates = []\n","\n","    for ent in doc.ents:\n","        if ent.label_ in [\"DATE\", \"TIME\"]:\n","            try:\n","                parsed_date = parser.parse(ent.text, fuzzy=True)\n","                extracted_dates.append(parsed_date.strftime(\"%Y-%m-%d %H:%M:%S\"))\n","            except:\n","                continue\n","\n","    return extracted_dates\n","\n","def detect_confirmation(text):\n","    \"\"\"D√©tecte si l'utilisateur donne une confirmation ou un refus.\"\"\"\n","    confirmations = LEXIQUE[\"expressions_confirmation\"]\n","    refus = LEXIQUE[\"expressions_negation\"]\n","\n","    text_lower = text.lower()\n","\n","    if any(word in text_lower for word in confirmations):\n","        return \"Confirmation\"\n","    elif any(word in text_lower for word in refus):\n","        return \"Refus\"\n","    else:\n","        return \"Incertitude\"\n","\n","def extract_verbs(text):\n","    \"\"\"Identifie les verbes conjugu√©s et leur infinitif.\"\"\"\n","    doc = nlp(text)\n","    verbs = [(token.text, token.lemma_) for token in doc if token.pos_ == \"VERB\"]\n","    return verbs"],"metadata":{"id":"zVYFD3oM4SQz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","\n","def init_LLM():\n","    MODEL_NAME = \"/content/drive/MyDrive/gemma-2b-it\"\n","    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n","\n","    # D√©tection du device\n","    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","    print(f\"Utilisation du device : {device}\")\n","\n","    # Chargement du mod√®le avec les param√®tres adapt√©s\n","    if device == \"cuda\":\n","        model = AutoModelForCausalLM.from_pretrained(\n","            MODEL_NAME,\n","            torch_dtype=torch.float16,\n","            device_map=\"auto\",\n","            trust_remote_code=True\n","        )\n","    else:\n","        model = AutoModelForCausalLM.from_pretrained(\n","            MODEL_NAME,\n","            torch_dtype=torch.float32,\n","            device_map={\"\": \"cpu\"},\n","            trust_remote_code=True\n","        )\n","    return tokenizer, model, device\n","\n","# Initialisation\n","tokenizer, model, device = init_LLM()\n","\n","def call_LLM(prompt):\n","    \"\"\"G√©n√®re une r√©ponse √† partir d'un prompt.\"\"\"\n","    # On transf√®re l'entr√©e sur le device appropri√©\n","    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n","    outputs = model.generate(\n","    **inputs,\n","    max_new_tokens=500,\n","    do_sample=True,\n","    temperature=0.7,\n","    repetition_penalty=1.2\n",")\n","\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","if __name__ == \"__main__\":\n","    while True:\n","        user_input = input(\"Vous : \")\n","        if user_input.lower() in [\"quit\", \"exit\"]:\n","            break\n","        response = call_LLM(user_input)\n","        print(\"Bot :\", response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["8c1d11fb80864647a9ffce52563395e2","2140b7a4deb94a2bba893497c09ea6f5","770c95dfe78a4758bc2827d30683b757","8d94dfcd76d34fb48155dc30fd246305","d468064cfa1b4387bca41780d096a14f","43390c5bd85d4b8bba1ca5476413cfcd","28368137b8f045c29cd3115a5132b3d6","76cdefc9a8ee4455ba2a73647f173501","5017957f9706404d836412964e1eabc8","415ef02408244d33b2fe914b2decfa7c","c7747625586249ee8904231135e9536d"]},"id":"1tjyzLerwVbT","executionInfo":{"status":"ok","timestamp":1741650490933,"user_tz":-60,"elapsed":516866,"user":{"displayName":"Chloem","userId":"00237808811430897591"}},"outputId":"4a150b78-8dc4-44d0-c831-edf61bf95973"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Utilisation du device : cuda\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c1d11fb80864647a9ffce52563395e2"}},"metadata":{}},{"name":"stdout","output_type":"stream","text":["Vous : Quelle est la derni√®re innovation en intelligence artificielle ? D√©tecte l‚Äôintention principale et r√©ponds uniquement avec l‚Äôintention.\n","Bot : Quelle est la derni√®re innovation en intelligence artificielle ? D√©tecte l‚Äôintention principale et r√©ponds uniquement avec l‚Äôintention.\n","\n","**L'objectif de cette intention est d'aider les gens √† comprendre comment fonctionnent les technologies r√©centes.** \n","\n","Vous : Quelle est la diff√©rence entre la 5G et la 6G ? D√©tecte l‚Äôintention principale et r√©ponds uniquement avec l‚Äôintention.\n","Bot : Quelle est la diff√©rence entre la 5G et la 6G ? D√©tecte l‚Äôintention principale et r√©ponds uniquement avec l‚Äôintention.\n","\n","**Intention:** Expliquer les diff√©rences entre 5G et 6G en termes de technologie.\n","\n","Vous : Quelles sont les avanc√©es r√©centes en informatique quantique ? D√©tecte l‚Äôintention principale et r√©ponds uniquement avec l‚Äôintention.\n","Bot : Quelles sont les avanc√©es r√©centes en informatique quantique ? D√©tecte l‚Äôintention principale et r√©ponds uniquement avec l‚Äôintention.\n","\n","**Intention principale : ** Fournir des informations sur les progr√®s r√©cents en informatique quantique. \n","\n","Vous : Peux-tu me parler des nouvelles technologies en cybers√©curit√© ? D√©tecte l‚Äôintention principale et r√©ponds uniquement avec l‚Äôintention.\n","Bot : Peux-tu me parler des nouvelles technologies en cybers√©curit√© ? D√©tecte l‚Äôintention principale et r√©ponds uniquement avec l‚Äôintention.\n","\n","**Nouvelles Technologies en Cybers√©curit√©**: \n","\n","* **L'apprentissage automatique (machine learning)** : Permet de cr√©er des mod√®les pour identifier les comportements anormaux, d√©tecter les intrusions ou pr√©dire les attaques potentielles.\n","* **La blockchain** : Offre une solution transparente et s√©curis√©e pour stocker et g√©rer les donn√©es sensibles.  \n","* **Le cryptage homomique** :  Permet d'assurer la confidentialit√© des informations par chiffrement robuste sans n√©cessiter un secret cl√© unique.\n","* **Les drones autonomes** :  Offrent un nouvel outil de surveillance et de protection gr√¢ce √† leur capacit√© de voler et de se d√©placer dans des environnements difficiles.\n","\n","\n","## Intention:\n","\n","D√©tecter l'intentions et analyser les avantages et les d√©fis des nouvelles technologies en cybers√©curit√©. \n","\n","Vous : Quelles avanc√©es a-t-on observ√©es en m√©decine connect√©e ? D√©tecte l‚Äôintention principale et r√©ponds uniquement avec l‚Äôintention\n","Bot : Quelles avanc√©es a-t-on observ√©es en m√©decine connect√©e ? D√©tecte l‚Äôintention principale et r√©ponds uniquement avec l‚Äôintention principale.\n","* **Intention :** Fournir des informations sur les progr√®s de la m√©decine connect√©e. \n","\n","\n","Les patients peuvent d√©sormais b√©n√©ficier d'une surveillance m√©dicale proactive gr√¢ce √† des technologies telles que le suivi du sommeil, de la fr√©quence cardiaque et de l'activit√© physique.  Des applications mobiles permettent √©galement aux utilisateurs d'avoir acc√®s √† un large √©ventail de donn√©es m√©dicales et √† une assistance virtuelle pour g√©rer leur sant√©.\n","\n","Ces innovations offrent des avantages importants, notamment : \n","\n","* Am√©lioration de la prise en charge globale de la maladie et de la pr√©vention des probl√®mes m√©dicaux. \n","* Faciliter les rendez-vous m√©dicaux et optimiser le temps pass√© dans les consultations. \n","* Offrir une meilleure compr√©hension de sa propre sant√© et des facteurs qui influencent son √©tat par rapport au contexte global.\n","\n","\n","\n","Vous : Quels sont les nouveaux processeurs en 2025 ? D√©tecte l‚Äôintention principale et r√©ponds uniquement avec l‚Äôintention.\n","Bot : Quels sont les nouveaux processeurs en 2025 ? D√©tecte l‚Äôintention principale et r√©ponds uniquement avec l‚Äôintention.\n","\n","**Intention: Fournir des informations sur les processeurs.**\n","\n","Vous : Pourquoi utilise-t-on les r√©seaux neuronaux en IA ? D√©tecte l‚Äôintention principale et r√©ponds uniquement avec l‚Äôintention.\n","Bot : Pourquoi utilise-t-on les r√©seaux neuronaux en IA ? D√©tecte l‚Äôintention principale et r√©ponds uniquement avec l‚Äôintention.\n","\n","Intention : Expliquer\n","\n","R√©ponses: Les r√©seaux de neurones sont utilis√©s dans l'IA car ils peuvent apprendre √† partir d'exemples, sans n√©cessiter des instructions pr√©cises pour chaque t√¢che. \n","\n","Vous : Qu‚Äôest-ce que l‚Äôedge computing ? D√©tecte l‚Äôintention principale et r√©ponds uniquement avec l‚Äôintention.\n","Bot : Qu‚Äôest-ce que l‚Äôedge computing ? D√©tecte l‚Äôintention principale et r√©ponds uniquement avec l‚Äôintention. \n","\n","L'objectif de cet article est d'expliquer ce qu'est l'Edge Computing en termes simples, sans fioritures inutiles.**\n","\n","\n","**D√©finition simple :** L'Edge Computing vient placer les serveurs informatiques plus pr√®s des utilisateurs afin de g√©rer plus efficacement les donn√©es trait√©es localement.**\n","\n","Vous : Vaut-il mieux un processeur Intel ou AMD ? D√©tecte l‚Äôintention principale et r√©ponds uniquement avec l‚Äôintention.\n","Bot : Vaut-il mieux un processeur Intel ou AMD ? D√©tecte l‚Äôintention principale et r√©ponds uniquement avec l‚Äôintention.\n","\n","**Intention:**  Comparaison de processeurs Intel vs AMD \n","\n","Vous : En quoi les batteries solides sont-elles meilleures que les batteries lithium-ion ? D√©tecte l‚Äôintention principale et r√©ponds uniquement avec l‚Äôintention.\n","Bot : En quoi les batteries solides sont-elles meilleures que les batteries lithium-ion ? D√©tecte l‚Äôintention principale et r√©ponds uniquement avec l‚Äôintention.\n","\n","**L'intention principale est de d√©montrer pourquoi les batteries solides sont plus performantes que les batteries lithium-ion.** \n","\n","\n","Les batteries solides offrent plusieurs avantages significatifs par rapport aux batteries lithium-ion, notamment :\n","\n","* **Fiabilit√© accrue** : Les batteries solides pr√©sentent une s√©curit√© am√©lior√©e gr√¢ce √† leur absence de risques d'√©mergence du m√©tal comme leLithium qui peut causer des incendies ou explosions.\n","* **Faible co√ªt**:  Le processus de fabrication des batteries solides est donc moins co√ªteux, ce qui signifie un prix d'achat en baisse pour ces derni√®res.\n","* **Durabilit√©:**  Elles peuvent √™tre r√©par√©es et r√©utilis√©s, augmentant ainsi la dur√©e de vie du produit.\n","* **Poids r√©duits:** L'absence de liquide inflammable r√©duit √©galement la masse globale des batteries solides.\n","\n","Par cons√©quent, les batteries solides constituent une alternative viable √† la batterie lithium-ion dans divers sc√©narios. \n","\n","\n","\n","\n","Vous : Quels sont les avantages et inconv√©nients de l‚ÄôIA symbolique face √† l‚ÄôIA connexionniste ? D√©tecte l‚Äôintention principale et r√©ponds uniquement avec l‚Äôintention.\n","Bot : Quels sont les avantages et inconv√©nients de l‚ÄôIA symbolique face √† l‚ÄôIA connexionniste ? D√©tecte l‚Äôintention principale et r√©ponds uniquement avec l‚Äôintention.\n","\n","**Intention : Comparer les deux types d'IA.** \n","\n","\n","##  Avantages et Inconv√©nients de l'IA Symbolique vs IA Connectionniste:\n"," \n","**IA Symbolique:**\n","\n","* **Avantages:** \n","    * Meilleure compr√©hension des concepts abstraits et non-quantifiables.\n","    * Plus facile √† adapter aux besoins sp√©cifiques, car elle s'appuie sur la connaissance humaine. \n","* **Inconv√©nients:** \n","    * Moins performante pour les t√¢ches complexes n√©cessitant une grande quantit√© de donn√©es. \n","    * Souvent plus lente en termes d'apprentissage et de prise de d√©cisions.\n","\n","\n","\n","\n","**IA Connexionniste:**\n","\n","* **Avantages:** \n","     * Excellente performance dans les probl√®mes li√©s √† la r√©solution de t√¢ches complexes.\n","     * Peut apprendre rapidement gr√¢ce √† l'ingestion massive de donn√©es.\n","* **Inconv√©nients:** \n","     * Difficult√© √† comprendre les intentions derri√®re les actions ou les r√©sultats. \n","     * Risquer de reproduire des biais pr√©sents dans les donn√©es qu'elle utilise.\n","\n","\n","\n","\n","Vous : Compare le stockage sur disque dur et SSD. D√©tecte l‚Äôintention principale et r√©ponds uniquement avec l‚Äôintention.\n","Bot : Compare le stockage sur disque dur et SSD. D√©tecte l‚Äôintention principale et r√©ponds uniquement avec l‚Äôintention.\n","\n","**Intention:** Expliquer les diff√©rences entre le stockage sur disque dur (HDD) et un Solid State Drive (SSD).\n","\n","\n","## Disque Dur vs. SSD: \n","Le **Disque Dur (HDD)** est une technologie de stockage magn√©tique qui utilise des plateaux magn√©tiques rotatifs pour stocker les donn√©es. Il offre plus d'espace √† moindre co√ªt, mais il peut √™tre lent. Le **Solid State Drive (SSD)** est une technologie de stockage flash qui utilise des cellules NAND pour stocker les donn√©es. Il est beaucoup plus rapide qu'une HDD, mais moins cher au volume.  \n","\n","En r√©sum√© :\n","\n","* **HDD:** Plus volumineux et moins cher, mais plus lent pour acc√©der aux donn√©es. \n","* **SSD:** Moins volumineux et plus cher, mais beaucoup plus rapide pour acc√©der aux donn√©es. \n","\n","\n","\n","\n","Vous : O√π puis-je trouver des articles sur les innovations en IA ? D√©tecte l‚Äôintention principale et r√©ponds uniquement avec l‚Äôintention.\n","Bot : O√π puis-je trouver des articles sur les innovations en IA ? D√©tecte l‚Äôintention principale et r√©ponds uniquement avec l‚Äôintention.\n","\n","The intention of the user is to find information about AI advancements and breakthroughs, as well as how these developments are being applied in various fields.  \n","\n","Vous : O√π lire les derni√®res recherches sur les robots autonomes ? D√©tecte l‚Äôintention principale et r√©ponds uniquement avec l‚Äôintention.\n","Bot : O√π lire les derni√®res recherches sur les robots autonomes ? D√©tecte l‚Äôintention principale et r√©ponds uniquement avec l‚Äôintention.\n","\n","**Intention:**  Fournir des informations pertinentes \n","\n","Vous : Quels sont les articles r√©cents sur le deep learning ? D√©tecte l‚Äôintention principale et r√©ponds uniquement avec l‚Äôintention.\n","Bot : Quels sont les articles r√©cents sur le deep learning ? D√©tecte l‚Äôintention principale et r√©ponds uniquement avec l‚Äôintention. \n","\n","**Note:** Veuillez fournir un bref r√©sum√© de l'intention du texte en une phrase ou moins.\n","\n","\n","Veuillez me donner des ressources pour explorer la recherche dans ce domaine, ainsi que quelques exemples concrets d'applications concr√®tes qui utilisent le deep learning.\n","\n","Vous : Quel est ton plat pr√©f√©r√©? D√©tecte l‚Äôintention principale et r√©ponds uniquement avec l‚Äôintention.\n","Bot : Quel est ton plat pr√©f√©r√©? D√©tecte l‚Äôintention principale et r√©ponds uniquement avec l‚Äôintention.\n","\n","**Intention:**  D√©tecter le type de r√©ponse en fonction de la question pos√©e. \n","\n","\n","Dans ce cas, la question pose une simple requ√™te pour savoir quel est le plat pr√©f√©r√© d'une personne. L'intention principale est donc d'identifier le plat pr√©f√©r√©.\n","\n","Vous : O√π se situe la Tour Eiffel? D√©tecte l‚Äôintention principale et r√©ponds uniquement avec l‚Äôintention.\n","Bot : O√π se situe la Tour Eiffel? D√©tecte l‚Äôintention principale et r√©ponds uniquement avec l‚Äôintention.\n","\n","**Intention :**  Donner des informations \n","\n","\n","La Tour Eiffel est situ√©e √† **Paris**, en France.\n","\n","Vous : Quelle est la capitale du Br√©sil ? D√©tecte l‚Äôintention principale et r√©ponds uniquement avec l‚Äôintention.\n","Bot : Quelle est la capitale du Br√©sil ? D√©tecte l‚Äôintention principale et r√©ponds uniquement avec l‚Äôintention. \n","**Intention: R√©ponse √† une question.**\n","\n","La r√©ponse : **Bras√≠lia**.  \n","\n","Vous : Quelle est la meilleure √©quipe de football ? D√©tecte l‚Äôintention principale et r√©ponds uniquement avec l‚Äôintention.\n","Bot : Quelle est la meilleure √©quipe de football ? D√©tecte l‚Äôintention principale et r√©ponds uniquement avec l‚Äôintention.\n","\n","**Intention:**  D√©tecter les intentions implicites des utilisateurs \n","\n","Vous : exit\n"]}]},{"cell_type":"code","source":["import json\n","import spacy\n","import torch\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","from sklearn.metrics import precision_score, recall_score, f1_score\n","\n","# Charger le mod√®le de langage naturel de spaCy\n","nlp = spacy.load(\"fr_core_news_md\")\n","\n","# Charger le mod√®le Gemma\n","MODEL_NAME = \"/content/drive/MyDrive/gemma-2b-it\"\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    MODEL_NAME,\n","    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n","    device_map=\"auto\" if device == \"cuda\" else {\"\": \"cpu\"},\n","    trust_remote_code=True\n",")\n","\n","# Charger le fichier de test (JSON contenant les phrases et r√©ponses attendues)\n","TEST_FILE = \"/content/drive/MyDrive/Projet4LLM/Corpus_dialogues_LLM.json\"\n","\n","with open(TEST_FILE, \"r\", encoding=\"utf-8\") as file:\n","    test_data = json.load(file)\n","\n","# Fonction pour appeler le LLM et g√©n√©rer une r√©ponse\n","def generate_response(prompt):\n","    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n","    outputs = model.generate(\n","        **inputs, max_new_tokens=100, do_sample=False\n","    )\n","    response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n","    return response\n","\n","# Fonction pour calculer la similarit√© de cosinus entre deux textes\n","def compute_similarity(text1, text2):\n","    doc1 = nlp(text1)\n","    doc2 = nlp(text2)\n","    return doc1.similarity(doc2)\n","\n","# Variables pour stocker les r√©sultats\n","true_labels = []\n","predicted_labels = []\n","similarity_scores = []\n","\n","# D√©finir un seuil de similarit√© pour consid√©rer une r√©ponse correcte\n","SIMILARITY_THRESHOLD = 0.5\n","\n","# √âvaluation du mod√®le\n","for item in test_data:\n","    phrase = item[\"Utilisateur\"]\n","    expected_response = item[\"Chatbot\"]\n","\n","    # G√©n√©rer une r√©ponse avec le mod√®le\n","    generated_response = generate_response(phrase)\n","\n","    # Calculer la similarit√© entre la r√©ponse attendue et la r√©ponse g√©n√©r√©e\n","    similarity = compute_similarity(expected_response, generated_response)\n","    similarity_scores.append(similarity)\n","\n","    # D√©terminer si la r√©ponse est correcte ou non\n","    is_correct = similarity > SIMILARITY_THRESHOLD\n","    true_labels.append(1)  # 1 = bonne r√©ponse\n","    predicted_labels.append(1 if is_correct else 0)\n","\n","    # Afficher les r√©sultats individuels\n","    print(f\"\\nüìå Phrase : {phrase}\")\n","    print(f\"‚úÖ R√©ponse attendue : {expected_response}\")\n","    print(f\"ü§ñ R√©ponse g√©n√©r√©e : {generated_response}\")\n","    print(f\"üìä Similarit√© : {similarity:.2f} {'‚úîÔ∏è Correct' if is_correct else '‚ùå Incorrect'}\")\n","\n","# Calcul des m√©triques\n","precision = precision_score(true_labels, predicted_labels, zero_division=1)\n","recall = recall_score(true_labels, predicted_labels, zero_division=1)\n","f1 = f1_score(true_labels, predicted_labels, zero_division=1)\n","accuracy = sum(predicted_labels) / len(predicted_labels)\n","\n","# Affichage des r√©sultats globaux\n","print(\"\\nüìä R√©sum√© de l'√©valuation :\")\n","print(f\"‚úîÔ∏è Taux de r√©ponses correctes : {accuracy * 100:.2f}%\")\n","print(f\"üéØ Pr√©cision : {precision:.2f}\")\n","print(f\"üì¢ Rappel : {recall:.2f}\")\n","print(f\"üèÜ F1-score : {f1:.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["a3a12b14b9bc47ca80c7f7c293c6c9c2","e56e2d519dc84f659cad73c10754f095","8734f40161f740fa886193be9e5ee878","82ea16cd6eec41b4b62058fecb921fa1","9765f86ce7f4457a9b11377dc1d2e6f3","d0fbdf54b5574780b35d1cb78cfde777","0b52c6dbc51e4ffe84278294bad008fd","d5f81f9f7f7645f1b7604c27736cf914","b036f3b04e4e40538c5a9a24278b63f2","04ea4260157f4ebdbbbdd298dcafd4d3","a816d7a628a140ee85e26ba7a664409c"]},"id":"aSgRPx11ix9V","executionInfo":{"status":"ok","timestamp":1741652791893,"user_tz":-60,"elapsed":428235,"user":{"displayName":"Chloem","userId":"00237808811430897591"}},"outputId":"ad7574aa-8385-46d5-9c2b-4cec1cc1cbc0"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3a12b14b9bc47ca80c7f7c293c6c9c2"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n"]},{"output_type":"stream","name":"stdout","text":["\n","üìå Phrase : Qu'est-ce que l'intelligence artificielle g√©n√©rative ?\n","‚úÖ R√©ponse attendue : L'intelligence artificielle g√©n√©rative est une branche de l'IA qui permet aux mod√®les de cr√©er du contenu original comme du texte, des images ou de la musique. Un exemple est ChatGPT-5, lanc√© en 2024.\n","ü§ñ R√©ponse g√©n√©r√©e : Qu'est-ce que l'intelligence artificielle g√©n√©rative ?\n","\n","L'intelligence artificielle g√©n√©rative (IA g√©n√©rative) est un type d'intelligence artificielle qui peut cr√©er de nouveaux contenus, tels que des images, des vid√©os, du texte, de la musique et m√™me du code. \n","\n","**Comment √ßa marche ?**\n","\n","L'IA g√©n√©rative utilise des mod√®les de machine learning, qui sont des algorithmes entra√Æn√©s sur de vastes ensembles de donn√©es. Ces mod√®les apprennent √† reconna√Ætre des patterns et des structures dans les donn√©es et peuvent\n","üìä Similarit√© : 0.89 ‚úîÔ∏è Correct\n","\n","üìå Phrase : Peux-tu m'en dire plus sur ChatGPT-5 ?\n","‚úÖ R√©ponse attendue : ChatGPT-5 est la cinqui√®me version du mod√®le de langage d√©velopp√© par OpenAI. Il offre une meilleure compr√©hension du contexte et g√©n√®re du texte plus pr√©cis. Il est utilis√© dans les chatbots, les assistants virtuels et la cr√©ation de contenu.\n","ü§ñ R√©ponse g√©n√©r√©e : Peux-tu m'en dire plus sur ChatGPT-5 ? \n","\n","Je suis curieux de savoir si c'est une version am√©lior√©e de ChatGPT-4, ou si c't'un mod√®le compl√®tement diff√©rent. \n","\n","Et si c'est un mod√®le diff√©rent, qu'est-ce qui le rend unique ?\n","üìä Similarit√© : 0.39 ‚ùå Incorrect\n","\n","üìå Phrase : Quels sont les derniers progr√®s en informatique quantique ?\n","‚úÖ R√©ponse attendue : En 2025, Microsoft a lanc√© la puce quantique **Majorana 1**, qui utilise des mat√©riaux supraconducteurs topologiques pour atteindre un million de qubits. Cette innovation est principalement utilis√©e en cryptographie avanc√©e et en calcul haute performance.\n","ü§ñ R√©ponse g√©n√©r√©e : Quels sont les derniers progr√®s en informatique quantique ?\n","\n","L'informatique quantique est un domaine en pleine expansion, avec de nouveaux progr√®s et d√©couvertes qui se produisent r√©guli√®rement. Voici quelques-uns des derniers d√©veloppements importants :\n","\n","**1. Am√©lioration de la stabilit√© et de la pr√©cision des qubits:**\n","\n","* **Nouvelles techniques de fabrication:** Des progr√®s dans la fabrication de qubits plus stables et plus fiables sont en cours. Des mat√©riaux innovants comme le silicium, le germanium et le diamant sont utilis√©s pour cr√©er des qubits\n","üìä Similarit√© : 0.85 ‚úîÔ∏è Correct\n","\n","üìå Phrase : La cybers√©curit√© a-t-elle connu des avanc√©es r√©centes ?\n","‚úÖ R√©ponse attendue : Oui, une avanc√©e majeure en 2024 est l‚Äôarchitecture **Secure Access Service Edge (SASE)**. Elle permet de combiner la s√©curit√© r√©seau et l‚Äôacc√®s cloud pour offrir une solution plus int√©gr√©e aux entreprises.\n","ü§ñ R√©ponse g√©n√©r√©e : La cybers√©curit√© a-t-elle connu des avanc√©es r√©centes ?\n","\n","**Oui, la cybers√©curit√© a connu de nombreuses avanc√©es r√©centes.** \n","\n","Voici quelques exemples :\n","\n","**1. L'intelligence artificielle (IA) et l'apprentissage automatique (ML) :**\n","\n","* **D√©tection et pr√©vention des attaques:** L'IA et le ML sont utilis√©s pour analyser les donn√©es en temps r√©el et d√©tecter les menaces potentielles, comme les attaques par ransomware ou les intrusions.\n","* **Automatisation des t√¢ches:** L'IA peut automat\n","üìä Similarit√© : 0.65 ‚úîÔ∏è Correct\n","\n","üìå Phrase : Que fait Apple dans l'intelligence artificielle ?\n","‚úÖ R√©ponse attendue : En 2024, Apple a int√©gr√© une intelligence artificielle g√©n√©rative dans l‚Äô**iPhone 16**, facilitant la recherche de photos et la g√©n√©ration automatique d‚Äô√©mojis.\n","ü§ñ R√©ponse g√©n√©r√©e : Que fait Apple dans l'intelligence artificielle ?\n","\n","Apple est un acteur majeur dans l'intelligence artificielle (IA). Voici quelques exemples de ce qu'Apple fait dans ce domaine :\n","\n","**1. Recherche et d√©veloppement:**\n","\n","* **Apple Research:** Apple investit massivement dans la recherche et le d√©veloppement de l'IA. Ils ont une √©quipe d√©di√©e √† l'IA qui travaille sur de nombreux projets, notamment sur la reconnaissance vocale, la vision par ordinateur, l'apprentissage automatique et la compr√©hension du langage naturel.\n","* **Apple\n","üìä Similarit√© : 0.82 ‚úîÔ∏è Correct\n","\n","üìå Phrase : Le stockage ADN est-il une technologie viable ?\n","‚úÖ R√©ponse attendue : Oui, le **Stockage ADN Synth√©tique** permet d‚Äôarchiver des donn√©es avec une densit√© et une durabilit√© in√©gal√©es. Il est utilis√© pour la conservation de grandes quantit√©s de donn√©es sur le long terme.\n","ü§ñ R√©ponse g√©n√©r√©e : Le stockage ADN est-il une technologie viable ?\n","\n","Le stockage ADN est une technologie prometteuse qui pourrait r√©volutionner le stockage de donn√©es. Cependant, il existe encore des d√©fis √† relever avant qu'elle ne devienne une technologie viable √† grande √©chelle.\n","\n","**Avantages:**\n","\n","* **Grande capacit√© de stockage:** L'ADN peut stocker une quantit√© astronomique de donn√©es, bien plus que les disques durs et les SSD actuels.\n","* **Faible consommation d'√©nergie:** L'ADN est un mat√©riau biologique qui ne n√©cessite pas d'\n","üìä Similarit√© : 0.87 ‚úîÔ∏è Correct\n","\n","üìå Phrase : Quelles innovations ont marqu√© le cloud computing en 2024 ?\n","‚úÖ R√©ponse attendue : Windows Server 2025 est une √©volution majeure dans le domaine, introduisant des am√©liorations en **s√©curit√©, virtualisation et int√©gration cloud**.\n","ü§ñ R√©ponse g√©n√©r√©e : Quelles innovations ont marqu√© le cloud computing en 2024 ?\n","\n","Le cloud computing a connu une ann√©e 2023 riche en innovations, et 2024 ne devrait pas √™tre diff√©rent. Voici quelques-unes des tendances qui pourraient √©merger :\n","\n","**1. L'intelligence artificielle (IA) et l'apprentissage automatique (ML) :**\n","\n","* **IA int√©gr√©e aux services cloud:** L'IA sera int√©gr√©e aux services cloud pour automatiser les t√¢ches, am√©liorer la s√©curit√© et offrir des exp√©riences utilisateur plus personnalis√©es.\n","* **D√©\n","üìä Similarit√© : 0.78 ‚úîÔ∏è Correct\n","\n","üìå Phrase : Comment le d√©veloppement logiciel devient-il plus √©cologique ?\n","‚úÖ R√©ponse attendue : En 2024, les **pratiques de codage √©cologiques** sont devenues populaires. Elles visent √† r√©duire l‚Äôempreinte carbone des logiciels en optimisant leur consommation √©nerg√©tique.\n","ü§ñ R√©ponse g√©n√©r√©e : Comment le d√©veloppement logiciel devient-il plus √©cologique ?\n","\n","Le d√©veloppement logiciel (SD) est un secteur en pleine croissance, mais il a √©galement un impact environnemental important.  Voici quelques pistes pour rendre le d√©veloppement logiciel plus √©cologique :\n","\n","**1. Optimisation des processus:**\n","\n","* **R√©duction des d√©placements:** En favorisant le travail √† distance, la collaboration en ligne et les outils de communication efficaces, on r√©duit les d√©placements et les √©missions de CO2.\n","* **Optimisation des ressources:** Utiliser des outils et des technologies plus perform\n","üìä Similarit√© : 0.83 ‚úîÔ∏è Correct\n","\n","üìå Phrase : La r√©alit√© virtuelle et augment√©e progressent-elles ?\n","‚úÖ R√©ponse attendue : Oui, en 2025, la **Fusion de la R√©alit√© Virtuelle et Augment√©e** a √©t√© une avanc√©e majeure, permettant des exp√©riences immersives plus r√©alistes dans les jeux, la formation et le design.\n","ü§ñ R√©ponse g√©n√©r√©e : La r√©alit√© virtuelle et augment√©e progressent-elles ?\n","\n","La r√©alit√© virtuelle (RV) et l'augmentation augment√©e (AR) sont des technologies en plein essor qui offrent des possibilit√©s r√©volutionnaires pour l'√©ducation, le divertissement et l'industrie. Cependant, ces technologies sont encore en d√©veloppement et pr√©sentent des d√©fis √† relever.\n","\n","**Avanc√©es notables:**\n","\n","* **Meilleure qualit√© d'image et de performance:** Les progr√®s technologiques ont permis de cr√©er des exp√©riences RV et AR plus immersives et r√©alistes. Les √©crans de\n","üìä Similarit√© : 0.83 ‚úîÔ∏è Correct\n","\n","üìå Phrase : √Ä quoi sert la 6G ?\n","‚úÖ R√©ponse attendue : La **6G**, dont le d√©ploiement a commenc√© en 2025, offre une latence r√©duite et des vitesses de connexion ultra-rapides, facilitant l'Internet des objets avanc√© et les communications intelligentes.\n","ü§ñ R√©ponse g√©n√©r√©e : √Ä quoi sert la 6G ?\n","\n","La 6G est une technologie de communication mobile qui promet des vitesses de t√©l√©chargement et d'upload encore plus rapides que la 5G. Elle est encore en d√©veloppement, mais elle pourrait r√©volutionner de nombreux domaines, notamment :\n","\n","**1. L'Internet des objets (IoT):** La 6G pourrait connecter des milliards d'objets, des voitures autonomes aux appareils domestiques, en fournissant une connexion ultra-rapide et fiable.\n","\n","**2. La r√©alit√© virtuelle et\n","üìä Similarit√© : 0.92 ‚úîÔ∏è Correct\n","\n","üìå Phrase : Qu'est-ce que l'**AI Swarm Intelligence** ?\n","‚úÖ R√©ponse attendue : C'est une technologie bas√©e sur des syst√®mes multi-agents qui imitent l‚Äôintelligence collective des colonies d‚Äôinsectes. Elle est utilis√©e pour l'optimisation logistique et la s√©curit√© collective.\n","ü§ñ R√©ponse g√©n√©r√©e : Qu'est-ce que l'**AI Swarm Intelligence** ?\n","\n","L'**AI Swarm Intelligence** (SI) est une approche d'intelligence artificielle qui s'inspire du comportement des colonies d'insectes, comme les abeilles, les termites ou les fourmis. \n","\n","**Comment √ßa marche ?**\n","\n","* **Simultan√©it√©:** Les agents de l'SI travaillent simultan√©ment, sans communication directe. \n","* **Individuel:** Chaque agent est un individu avec ses propres capacit√©s et ses propres objectifs. \n","* **Collaboration\n","üìä Similarit√© : 0.49 ‚ùå Incorrect\n","\n","üìå Phrase : Peut-on combiner l'IA, l‚Äôinformatique quantique et la robotique ?\n","‚úÖ R√©ponse attendue : Oui, en 2025, la **Convergence de l'IA, de l'Informatique Quantique et de la Robotique** a permis de cr√©er des √©cosyst√®mes interconnect√©s pour l'automatisation industrielle et la gestion intelligente des villes.\n","ü§ñ R√©ponse g√©n√©r√©e : Peut-on combiner l'IA, l‚Äôinformatique quantique et la robotique ?\n","\n","**Oui, et c'est une combinaison prometteuse qui pourrait r√©volutionner de nombreux domaines.**\n","\n","**Voici quelques exemples de ce qui pourrait √™tre possible:**\n","\n","* **Optimisation des processus industriels:** L'IA peut analyser les donn√©es en temps r√©el et identifier les inefficacit√©s. L'informatique quantique peut aider √† r√©soudre des probl√®mes complexes et √† optimiser les processus de production. La robotique peut ensuite √™tre utilis√©e pour mettre en ≈ìuvre ces optimisations.\n","* **\n","üìä Similarit√© : 0.85 ‚úîÔ∏è Correct\n","\n","üìä R√©sum√© de l'√©valuation :\n","‚úîÔ∏è Taux de r√©ponses correctes : 83.33%\n","üéØ Pr√©cision : 1.00\n","üì¢ Rappel : 0.83\n","üèÜ F1-score : 0.91\n"]}]}]}